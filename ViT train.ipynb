{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d14456a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fano\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from vit import utils, vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a97bf499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e24354c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Flatten, Dropout, Activation, Input, Lambda\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a51a27b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d34ead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2022\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96e487c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_label), (test_data, test_label) = cifar10.load_data()\n",
    "train_label = to_categorical(train_label)\n",
    "test_label = to_categorical(test_label)\n",
    "train_data = (train_data/255.).astype(\"float32\")\n",
    "test_data = (test_data/255.).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "417e5ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_data, train_label, random_state=seed, shuffle=True,train_size=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c80b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "datagen = ImageDataGenerator(rotation_range=15, width_shift_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "train_generator = datagen.flow(X_train, y_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5b23ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_vit = ModelCheckpoint(r'C:\\Users\\fano\\Desktop\\weights\\vit4_6.h5', \n",
    "    verbose=1, \n",
    "    monitor='val_loss',\n",
    "    save_best_only=True, \n",
    "    mode='auto'\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9422c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (32, 32, 3) #Cifar10 image size\n",
    "image_size = 32 #size after resizing image\n",
    "num_classes = 10\n",
    "\n",
    "def build_model():\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Lambda(lambda image: tf.image.resize(image, (image_size, image_size)))(inputs) #Resize image to  size 224x224\n",
    "    base_model = vit.vit_b4(image_size=image_size, activation=\"sigmoid\", pretrained=False,\n",
    "                            include_top=False, pretrained_top=False)\n",
    "    \n",
    "    base_model.trainable = False #Set false for transfer learning\n",
    "    x = base_model(x)\n",
    "    x = Flatten()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(32, activation=tf.keras.activations.gelu)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model_final = Model(inputs=inputs, outputs=outputs)\n",
    "    return model_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bc6f9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      " vit-b8 (Functional)         (None, 768)               85144320  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 768)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 768)              3072      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                24608     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,172,458\n",
      "Trainable params: 26,538\n",
      "Non-trainable params: 85,145,920\n",
      "_________________________________________________________________\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23048"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "print(\"\\n\")\n",
    "# model.fit(train_generator,\n",
    "#           steps_per_epoch=200,\n",
    "#           epochs=2,\n",
    "#           validation_data=(X_valid, y_valid),\n",
    "#          )\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3786ca1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " lambda_1 (Lambda)           (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      " vit-b8 (Functional)         (None, 768)               85144320  \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 768)               0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 768)              3072      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                24608     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,172,458\n",
      "Trainable params: 85,170,858\n",
      "Non-trainable params: 1,600\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "Epoch 1/50\n",
      "2813/2813 [==============================] - 483s 167ms/step - loss: 1.8926 - accuracy: 0.3188 - val_loss: 1.8733 - val_accuracy: 0.3174\n",
      "Epoch 2/50\n",
      "2813/2813 [==============================] - 464s 165ms/step - loss: 1.6904 - accuracy: 0.3931 - val_loss: 1.5922 - val_accuracy: 0.4304\n",
      "Epoch 3/50\n",
      "2813/2813 [==============================] - 459s 163ms/step - loss: 1.6155 - accuracy: 0.4236 - val_loss: 1.5742 - val_accuracy: 0.4356\n",
      "Epoch 4/50\n",
      "2813/2813 [==============================] - 460s 164ms/step - loss: 1.5699 - accuracy: 0.4384 - val_loss: 1.4754 - val_accuracy: 0.4716\n",
      "Epoch 5/50\n",
      "2813/2813 [==============================] - 463s 165ms/step - loss: 1.5257 - accuracy: 0.4532 - val_loss: 1.4295 - val_accuracy: 0.4912\n",
      "Epoch 6/50\n",
      "1313/2813 [=============>................] - ETA: 4:01 - loss: 1.4917 - accuracy: 0.4684"
     ]
    }
   ],
   "source": [
    "plateau = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, verbose=1)\n",
    "model = build_model()\n",
    "#Switch ViT layer to trainable for fine tuning\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "#Requires compile again to activate trainable=True\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "print(\"\\n\")\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "#                     steps_per_epoch=200, \n",
    "                    epochs=50,\n",
    "                    validation_data=(X_valid, y_valid)\n",
    "                   )\n",
    "print(\"\\nTest Accuracy: \", accuracy_score(np.argmax(test_label, axis=1), np.argmax(model.predict(test_data), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f29eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47b9d54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40f373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_data,test_label, batch_size=32, verbose=1)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda5569a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
